{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in /Users/kaushikmedamanuri/anaconda3/envs/tensorflow/lib/python3.11/site-packages (0.10.9)\n",
      "Requirement already satisfied: opencv-python in /Users/kaushikmedamanuri/anaconda3/envs/tensorflow/lib/python3.11/site-packages (4.9.0.80)\n",
      "Requirement already satisfied: absl-py in /Users/kaushikmedamanuri/anaconda3/envs/tensorflow/lib/python3.11/site-packages (from mediapipe) (2.1.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in /Users/kaushikmedamanuri/anaconda3/envs/tensorflow/lib/python3.11/site-packages (from mediapipe) (23.1.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /Users/kaushikmedamanuri/anaconda3/envs/tensorflow/lib/python3.11/site-packages (from mediapipe) (23.5.26)\n",
      "Requirement already satisfied: matplotlib in /Users/kaushikmedamanuri/anaconda3/envs/tensorflow/lib/python3.11/site-packages (from mediapipe) (3.7.2)\n",
      "Requirement already satisfied: numpy in /Users/kaushikmedamanuri/anaconda3/envs/tensorflow/lib/python3.11/site-packages (from mediapipe) (1.25.1)\n",
      "Requirement already satisfied: opencv-contrib-python in /Users/kaushikmedamanuri/anaconda3/envs/tensorflow/lib/python3.11/site-packages (from mediapipe) (4.9.0.80)\n",
      "Requirement already satisfied: protobuf<4,>=3.11 in /Users/kaushikmedamanuri/anaconda3/envs/tensorflow/lib/python3.11/site-packages (from mediapipe) (3.20.3)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in /Users/kaushikmedamanuri/anaconda3/envs/tensorflow/lib/python3.11/site-packages (from mediapipe) (0.4.6)\n",
      "Requirement already satisfied: CFFI>=1.0 in /Users/kaushikmedamanuri/anaconda3/envs/tensorflow/lib/python3.11/site-packages (from sounddevice>=0.4.4->mediapipe) (1.15.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/kaushikmedamanuri/anaconda3/envs/tensorflow/lib/python3.11/site-packages (from matplotlib->mediapipe) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/kaushikmedamanuri/anaconda3/envs/tensorflow/lib/python3.11/site-packages (from matplotlib->mediapipe) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/kaushikmedamanuri/anaconda3/envs/tensorflow/lib/python3.11/site-packages (from matplotlib->mediapipe) (4.41.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/kaushikmedamanuri/anaconda3/envs/tensorflow/lib/python3.11/site-packages (from matplotlib->mediapipe) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/kaushikmedamanuri/anaconda3/envs/tensorflow/lib/python3.11/site-packages (from matplotlib->mediapipe) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/kaushikmedamanuri/anaconda3/envs/tensorflow/lib/python3.11/site-packages (from matplotlib->mediapipe) (10.0.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /Users/kaushikmedamanuri/anaconda3/envs/tensorflow/lib/python3.11/site-packages (from matplotlib->mediapipe) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/kaushikmedamanuri/anaconda3/envs/tensorflow/lib/python3.11/site-packages (from matplotlib->mediapipe) (2.8.2)\n",
      "Requirement already satisfied: pycparser in /Users/kaushikmedamanuri/anaconda3/envs/tensorflow/lib/python3.11/site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\n",
      "Requirement already satisfied: six>=1.5 in /Users/kaushikmedamanuri/anaconda3/envs/tensorflow/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install mediapipe opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_holistic = mp.solutions.holistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([32.49, -39.96,-3.86])\n",
    "b = np.array([31.39, -39.28, -4.66])\n",
    "c = np.array([31.14, -38.09,-4.49])\n",
    "\n",
    "def calc_angle(a, b, c):\n",
    "\n",
    "    a = np.array([a.x, a.y, a.z])\n",
    "    b = np.array([b.x, b.y, b.z])\n",
    "    c = np.array([c.x, c.y, c.z])\n",
    "\n",
    "\n",
    "    ba = a - b\n",
    "    bc = c - b\n",
    "\n",
    "    print(\"Ba:\" + str(ba))\n",
    "    print(\"BC:\" + str(bc))\n",
    "\n",
    "    cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n",
    "    angle = np.arccos(cosine_angle)\n",
    "\n",
    "    return np.degrees(angle)\n",
    "\n",
    "def get_dist(a, b):\n",
    "    return np.linalg.norm(np.array([b.x, b.y, b.z]) - np.array([a.x, a.y, a.z]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import traceback\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Set up OpenCV window\n",
    "# Changed the window title to 'Deadlift Form Corrector'\n",
    "cv2.namedWindow('Deadlift Form Corrector', cv2.WINDOW_NORMAL)\n",
    "# Resized the window to 1200x600 pixels for a wider view\n",
    "cv2.resizeWindow('Deadlift Form Corrector', 1200, 600)\n",
    "\n",
    "# Curl counter variables\n",
    "counter = 0\n",
    "stage = None\n",
    "\n",
    "alr_ran = False\n",
    "og_l_should_pos = 0\n",
    "og_r_should_pos = 0\n",
    "\n",
    "state = \"none\"\n",
    "reps = 0\n",
    "\n",
    "\n",
    "\n",
    "# Setup mediapipe instance\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic, mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor image to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "      \n",
    "        # Make detection\n",
    "        results = pose.process(image)\n",
    "        results_face = holistic.process(image)\n",
    "    \n",
    "        # Recolor back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        stage = []\n",
    "        # Extract landmarks\n",
    "        try:\n",
    "            #print(\"Testing\")\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            # Get coordinates\n",
    "            \n",
    "            #print(landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value])\n",
    "            hip_dist = get_dist(landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value], landmarks[mp_pose.PoseLandmark.LEFT_HIP.value])\n",
    "            ankle_dist = get_dist(landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value], landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value])\n",
    "\n",
    "            wrist_dist = get_dist(landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value], landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value])\n",
    "            shoulder_dist = get_dist(landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value], landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value])\n",
    "            \n",
    "            l_shoulder_hip_dist = get_dist(landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value], landmarks[mp_pose.PoseLandmark.LEFT_HIP.value])\n",
    "            r_shoulder_hip_dist = get_dist(landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value], landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value])\n",
    "\n",
    "\n",
    "            right_elbow_angle = calc_angle(landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value], landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value], \n",
    "                                          landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value])\n",
    "            left_elbow_angle = calc_angle(landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value], landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value], \n",
    "                                          landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value])\n",
    "\n",
    "            right_knee_angle = calc_angle(landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value], landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value], \n",
    "                                          landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value])\n",
    "\n",
    "            left_knee_angle = calc_angle(landmarks[mp_pose.PoseLandmark.LEFT_HIP.value], landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value], \n",
    "                                          landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value])\n",
    "\n",
    "\n",
    "            new_state = \"\"\n",
    "            if left_knee_angle >= 120 or right_knee_angle >= 120:\n",
    "                new_state = \"up\"\n",
    "\n",
    "            if left_knee_angle <= 80 or right_knee_angle <= 80:\n",
    "                new_state = \"down\"\n",
    "            \n",
    "            if state == \"up\" and new_state == \"down\":\n",
    "                reps += 1\n",
    "            \n",
    "            state = new_state\n",
    "\n",
    "\n",
    "            #print(\"Right knee:\" + str(landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value]))\n",
    "            #print(\"Right hip:\" + str(landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value]))\n",
    "\n",
    "            # cv2.putText(image, \"Hip dis:\" + str(hip_dis), \n",
    "            #                 (200,200), \n",
    "            #                 cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            # cv2.putText(image, \"Left Elbow Angle:\" + str(round(left_elbow_angle, 4)), \n",
    "            #                 (300,300), \n",
    "            #                 cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            # cv2.putText(image, \"Left Knee Angle:\" + str(round(left_knee_angle, 4)), \n",
    "            #                 (400,400), \n",
    "            #                 cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "\n",
    "            #These are the arm angles to see if the user is spreading/moving their arms too much\n",
    "            # cv2.putText(image, str(l_arm_angle), \n",
    "            #                 tuple(np.multiply(l_shoulder, [640, 480]).astype(int)), \n",
    "            #                 cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            # cv2.putText(image, str(r_arm_angle), \n",
    "            #                 tuple(np.multiply(r_shoulder, [640, 480]).astype(int)), \n",
    "            #                 cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA\n",
    "            #                      )\n",
    "\n",
    "            \n",
    "            # Checking Logic\n",
    "            \n",
    "            if hip_dist / ankle_dist > 0.65:\n",
    "                stage.append(\"Your legs are too narrow\")\n",
    "            if hip_dist / ankle_dist < 0.4:\n",
    "                stage.append(\"Your legs are too wide\") \n",
    "            if shoulder_dist / wrist_dist > 1:\n",
    "                stage.append(\"Move your arms farther apart on the bar\")\n",
    "            if shoulder_dist / wrist_dist < 0.58:\n",
    "                stage.append(\"Move your arms close together on the bar\")  \n",
    "\n",
    "            if left_elbow_angle < 120:\n",
    "                stage.append(\"Keep your arms straight, it can strain your elbows\")\n",
    "            \n",
    "            if left_knee_angle < 50 or right_knee_angle < 50:\n",
    "                stage.append(\"Don't bend down too much, it can strain your knees\")\n",
    "            \n",
    "            if len(stage) == 0:\n",
    "                    stage.append(\"Great Form!\")# Render video frame to the left\n",
    "\n",
    "\n",
    "                       \n",
    "        except Exception:\n",
    "            traceback.print_exc()\n",
    "        \n",
    "        # Render curl counter\n",
    "\n",
    "# Setup s# Render video frame to the left\n",
    "        # Changed the color of the status box to blue\n",
    "        #cv2.rectangle(image, (0, 0), (720, 130), (0, 0, 255), -1)\n",
    "\n",
    "        # Render project title\n",
    "        cv2.putText(image, 'MotionMentor Deadlift Form Corrector', (540, 40),  # Centered at the top\n",
    "                    cv2.FONT_HERSHEY_DUPLEX, 1.3, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "        # Render blue box with text at the top\n",
    "        #cv2.rectangle(image, (0, 0), (1200, 60), (70, 130, 180), -1)  # Blue box\n",
    "        # Stage data\n",
    "        # cv2.putText(image, 'MOTION MENTOR', (550,30), \n",
    "        #             cv2.FONT_HERSHEY_TRIPLEX, 1, (255,255,255), 1, cv2.LINE_AA)\n",
    "        \n",
    "        # cv2.putText(image, \"Reps: \" + str(reps), \n",
    "        #                     (1000,100), \n",
    "        #                     cv2.FONT_HERSHEY_DUPLEX, 1.8, (255,255,255), 2, cv2.LINE_AA)\n",
    "\n",
    "        if(len(stage) == 0):\n",
    "            continue\n",
    "        elif stage[0] == \"Great Form!\":\n",
    "            cv2.putText(image, stage[0], \n",
    "                            (30,100), \n",
    "                            cv2.FONT_HERSHEY_DUPLEX, 1.8, (0,255,0), 2, cv2.LINE_AA)\n",
    "        else:\n",
    "            i = 0\n",
    "            for x in stage:\n",
    "                cv2.putText(image, x,\n",
    "                            (30,120 + i*60), \n",
    "                            cv2.FONT_HERSHEY_DUPLEX, 1.5, (0,0,255), 2, cv2.LINE_AA)\n",
    "                i += 1\n",
    "\n",
    "        print(stage)\n",
    "        \n",
    "        \n",
    "        # Render detections\n",
    "        mp_drawing.draw_landmarks(image, results_face.face_landmarks, mp_holistic.FACEMESH_TESSELATION)\n",
    "        \n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                mp_drawing.DrawingSpec(color=(0,255,0), thickness=2, circle_radius=2), \n",
    "                                mp_drawing.DrawingSpec(color=(0,0,255), thickness=2, circle_radius=2) \n",
    "                                 )               \n",
    "                                 \n",
    "        \n",
    "        cv2.imshow('Deadlift Form Corrector', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
